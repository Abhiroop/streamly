{-# LANGUAGE ConstraintKinds           #-}
{-# LANGUAGE FlexibleContexts          #-}
{-# LANGUAGE ScopedTypeVariables       #-}

module Asyncly.Threads
    ( MonadAsync
    , wait
    , wait_
    , threads

    , async
    , makeAsync
    , each
    , gather

    , waitLogged
    , waitLogged_
    , logged
    , suspend
    , withLog
    , eachWithLog
    )
where

import           Control.Applicative         ((<|>), empty)
import           Control.Concurrent          (ThreadId, forkIO, killThread,
                                              myThreadId)
import           Control.Concurrent.STM      (TChan, atomically, newTChan,
                                              readTChan, tryReadTChan,
                                              writeTChan)
import           Control.Exception           (SomeException (..))
import qualified Control.Exception.Lifted    as EL
import           Control.Monad.Catch         (MonadCatch, MonadThrow, throwM,
                                              try)
import           Control.Monad.IO.Class      (MonadIO (..))
import           Control.Monad.State         (get, gets, modify, mzero, put,
                                              runStateT, when, StateT)
import           Control.Monad.Trans.Class   (MonadTrans (lift))
import           Control.Monad.Trans.Control (MonadBaseControl, liftBaseWith)
import           Data.IORef                  (IORef, atomicModifyIORef,
                                              modifyIORef, newIORef, readIORef,
                                              writeIORef)
import           Data.List                   (delete)
import           Data.Maybe                  (isJust)
import           Unsafe.Coerce               (unsafeCoerce)

import           Asyncly.AsyncT

type MonadAsync m = (MonadIO m, MonadBaseControl IO m, MonadThrow m)

------------------------------------------------------------------------------
-- Model of computation
------------------------------------------------------------------------------

-- A computation starts in a top level thread. If no "forking primitives" are
-- used then the thread finishes in a straight line flow just like the IO
-- monad. However, if a "forking primitive" is used it "forks" the computation
-- into multiple flows.  The "forked" computations may run concurrently (and
-- therefore in parallel when possible) or serially. When multiple forking
-- primitives are composed it results into a tree of computations where each
-- branch of the tree can run concurrently.
--
-- A forking primitive may create multiple forks at that point, each fork
-- provides a specific input value to be used in the forked computation, this
-- value defines the fork.
--
-- The final result of the computation is the collection of all the values
-- generated by all the leaf level forks. These values are then propagated up
-- the tree and collected at the root of the tree.
--
-- Since AsyncT is a transformer we can use things like pipe, conduit or any
-- other transformer monads inside the computations to utilize single threaded
-- composition or data flow techniques.
--
------------------------------------------------------------------------------
-- Pick up from where we left in the previous thread
------------------------------------------------------------------------------

-- | Continue execution of the closure that we were executing when we migrated
-- to a new thread.

runContext :: Monad m => Context -> AsyncT m a -> StateT Context m ()
runContext ctx action = do
    let s = runAsyncT $ action >>= unsafeCoerce (continuation ctx)
    _ <- lift $ runStateT s ctx
    return ()

------------------------------------------------------------------------------
-- Thread Management (creation, reaping and killing)
------------------------------------------------------------------------------

-- XXX We are using unbounded channels so this will not block on writing to
-- pchan. We can use bounded channels to throttle the creation of threads based
-- on consumption rate.
processOneEvent :: MonadIO m
    => ChildEvent
    -> [ThreadId]
    -> m ([ThreadId], Maybe SomeException)
processOneEvent (ChildDone tid e) pending = do
    when (isJust e) $ liftIO $ mapM_ killThread pending
    return (delete tid pending, Nothing)

drainChildren :: MonadIO m
    => TChan ChildEvent
    -> [ThreadId]
    -> m ([ThreadId], Maybe SomeException)
drainChildren cchan pending =
    case pending of
        [] -> return (pending, Nothing)
        _  ->  do
            ev <- liftIO $ atomically $ readTChan cchan
            (p, e) <- processOneEvent ev pending
            maybe (drainChildren cchan p) (const $ return (p, e)) e

waitForChildren :: MonadIO m => Context -> m (Maybe SomeException)
waitForChildren ctx = do
    let pendingRef = pendingThreads ctx
    pending <- liftIO $ readIORef pendingRef
    (p, e) <- drainChildren (childChannel ctx) pending
    liftIO $ writeIORef pendingRef p
    return e

tryReclaimZombies :: (MonadIO m, MonadThrow m) => Context -> m ()
tryReclaimZombies ctx = do
    let cchan = childChannel ctx
        pendingRef = pendingThreads ctx

    pending <- liftIO $ readIORef pendingRef
    case pending of
        [] -> return ()
        _ ->  do
            mev <- liftIO $ atomically $ tryReadTChan cchan
            case mev of
                Nothing -> return ()
                Just ev -> do
                    (p, e) <- processOneEvent ev pending
                    liftIO $ writeIORef pendingRef p
                    maybe (return ()) throwM e
                    tryReclaimZombies ctx

waitForOneEvent :: (MonadIO m, MonadThrow m) => Context -> m ()
waitForOneEvent ctx = do
    -- XXX assert pending must have at least one element
    -- assert that the tid is found in our list
    let cchan = childChannel ctx
        pendingRef = pendingThreads ctx

    ev <- liftIO $ atomically $ readTChan cchan
    pending <- liftIO $ readIORef pendingRef
    (p, e) <- processOneEvent ev pending
    liftIO $ writeIORef pendingRef p
    maybe (return ()) throwM e

-- XXX this is not a real semaphore as it does not really block on wait,
-- instead it returns whether the value is zero or non-zero.
--
waitQSemB :: IORef Int -> IO Bool
waitQSemB   sem = atomicModifyIORef sem $ \n ->
                    if n > 0
                    then (n - 1, True)
                    else (n, False)

signalQSemB :: IORef Int -> IO ()
signalQSemB sem = atomicModifyIORef sem $ \n -> (n + 1, ())

-- Allocation of threads
--
-- global thread limit
-- thread fan-out i.e. per thread children limit
-- min per thread allocation to avoid starvation
--
-- dynamic adjustment based on the cost, speed of consumption, cpu utilization
-- etc. We need to adjust the limits based on cost, throughput and latencies.
--
-- The event producer thread must put the work on a work-queue and the child
-- threads can pick it up from there. But if there is just one consumer then it
-- may not make sense to have a separate producer unless the producing cost is
-- high.
--

forkFinally1 :: (MonadIO m, MonadBaseControl IO m)
    => Context
    -> AsyncT m a
    -> (Either SomeException () -> IO ())
    -> StateT Context m ThreadId
forkFinally1 ctx action preExit =
    EL.mask $ \restore ->
        liftBaseWith $ \runInIO -> forkIO $ do
            _ <- runInIO $ EL.try (restore (runContext ctx action))
                           >>= liftIO . preExit
            -- XXX restore state here
            return ()

-- | Run a given context in a new thread.
--
forkContext :: (MonadBaseControl IO m, MonadIO m, MonadThrow m)
    => AsyncT m a -> StateT Context m ()
forkContext action = do
    parentCtx <- get
    childCtx <- childContext parentCtx
    tid <- forkFinally1 childCtx action
                (beforeExit childCtx (childChannel parentCtx))
    updatePendingThreads parentCtx tid

    where

    updatePendingThreads :: (MonadIO m, MonadThrow m)
        => Context -> ThreadId -> m ()
    updatePendingThreads ctx tid = do
        -- update the new thread before reclaiming zombies so that if it exited
        -- already reclaim finds it in the list and does not panic.
        liftIO $ modifyIORef (pendingThreads ctx) $ (\ts -> tid:ts)
        tryReclaimZombies ctx

    childContext ctx = do
        pendingRef <- liftIO $ newIORef []
        chan <- liftIO $ atomically newTChan
        -- shares the threadCredit of the parent by default
        return $ ctx
            { pendingThreads = pendingRef
            , childChannel = chan
            }

    beforeExit ctx pchan res = do
        tid <- myThreadId
        r <- case res of
            Left e -> do
                dbg $ "beforeExit: " ++ show tid ++ " caught exception"
                liftIO $ readIORef (pendingThreads ctx) >>= mapM_ killThread
                return (Just e)
            Right _ -> waitForChildren ctx

        signalQSemB (threadCredit ctx)
        liftIO $ atomically $ writeTChan pchan (ChildDone tid r)

-- | Decide whether to resume the context in the same thread or a new thread
--
canFork :: Context -> IO Bool
canFork context = do
    gotCredit <- liftIO $ waitQSemB (threadCredit context)
    case gotCredit of
        False -> do
            pending <- liftIO $ readIORef $ pendingThreads context
            case pending of
                [] -> return False
                _ -> do
                        -- XXX If we have unreclaimable child threads e.g.
                        -- infinite loop, this is going to deadlock us. We need
                        -- special handling for those cases. Add those to
                        -- unreclaimable list? And always execute them in an
                        -- async thread, cannot use sync for those.
                        --
                        waitForOneEvent context
                        canFork context
        True -> return True

-- | Resume a captured context with a given action. The context may be resumed
-- in the same thread or in a new thread depending on the synch parameter and
-- the current thread quota.
--
resumeContextWith :: MonadAsync m
    => Bool             -- force synchronous
    -> AsyncT m a
    -> StateT Context m ()
resumeContextWith synch action = do
    context <- get
    can <- liftIO $ canFork context
    case can && (not synch) of
        False -> runContext context action
        True -> forkContext action

-- The current model is to start a new thread for every task. The input is
-- provided at the time of the creation and therefore no synchronization is
-- needed compared to a pool of threads contending to get the input from a
-- channel. However the thread creation overhead may be more than the
-- synchronization cost?
--
-- When the task is over the outputs need to be collected and that requires
-- synchronization irrespective of a thread pool model or per task new thread
-- model.
--
-- XXX instead of starting a new thread every time, reuse the existing child
-- threads and send them work via a shared channel. When there is no more work
-- available we need a way to close the channel and wakeup all waiters so that
-- they can go away rather than waiting indefinitely.
--

-- Housekeeping, invoked after spawning of all child tasks is done and the
-- parent task needs to terminate. Either the task is fully done or we handed
-- it over to another thread, in any case the current thread is done.

spawningParentDone :: MonadIO m => StateT Context m (Maybe a)
spawningParentDone = do
    loc <- getLocation
    when (loc /= RemoteNode) $ setLocation WaitingParent
    return Nothing

-- If a new thread cannot be created then the computation is run in the same
-- thread, but the functional behavior remains the same.

async :: MonadAsync m => AsyncT m a -> AsyncT m a
async action = AsyncT $ do
    resumeContextWith False action
    spawningParentDone

-- | Makes an asyncly action from a callback setter function; can be used to
-- convert existing callback style code into asyncly style code.  The first
-- parameter is a callback setter function.  When we are called back,
-- 'makeAsync' behaves as if it was an async computation that just returned a
-- value of type 'a'.  After the computation is done the result of the action
-- in second parameter is returned to the callback.
--
makeAsync :: MonadAsync m => ((a -> m ()) -> m ()) -> AsyncT m a
makeAsync cbsetter = AsyncT $ do
    -- XXX should we force fork a thread or keep running the context of the
    -- callback?
    ctx <- get
    lift $ cbsetter $ \a -> do
            let s = resumeContextWith False (return a)
            _ <- runStateT s ctx
            return ()
    spawningParentDone

-- scatter
each :: (MonadIO m, MonadBaseControl IO m, MonadThrow m)
    => [a] -> AsyncT m a
each xs = foldl (<|>) empty $ map (async . return) xs

------------------------------------------------------------------------------
-- Controlling thread quota
------------------------------------------------------------------------------

-- XXX Should n be Word32 instead?
-- | Runs a computation under a given thread limit.  A limit of 0 means new
-- tasks start synchronously in the current thread.  New threads are created by
-- 'parallel', and APIs that use parallel.
threads :: MonadIO m => Int -> AsyncT m a -> AsyncT m a
threads n process = AsyncT $ do
   oldCr <- gets threadCredit
   newCr <- liftIO $ newIORef n
   modify $ \s -> s { threadCredit = newCr }
   r <- runAsyncT $ process
        <** (AsyncT $ do
            modify $ \s -> s { threadCredit = oldCr }
            return (Just ())
            ) -- restore old credit
   return r

{-
-- This can be used to set, increase or decrease the existing limit. The limit
-- is shared by multiple threads and therefore needs to modified atomically.
-- Note that when there is no limit the limit is set to maxBound it can
-- overflow with an increment and get reduced instead of increasing.
-- XXX should we use a Maybe instead? Or use separate inc/dec/set APIs to
-- handle overflow properly?
--
-- modifyThreads :: MonadIO m => (Int -> Int) -> AsyncT m ()
-- modifyThreads f =
-}

------------------------------------------------------------------------------
-- Running the monad
------------------------------------------------------------------------------

-- | Run an 'AsyncT m' computation and collect the results generated by each
-- thread of the computation in a list.
waitAsync :: (MonadIO m, MonadCatch m)
    => (a -> AsyncT m a) -> Maybe (IORef [Log]) -> AsyncT m a -> m ()
waitAsync finalizer lref m = do
    childChan  <- liftIO $ atomically newTChan
    pendingRef <- liftIO $ newIORef []
    credit     <- liftIO $ newIORef maxBound

    let ctx = initContext childChan pendingRef credit finalizer lref

    r <- try $ runStateT (runAsyncT $ m >>= finalizer) ctx

    case r of
        Left (exc :: SomeException) -> do
            liftIO $ readIORef pendingRef >>= mapM_ killThread
            throwM exc
        Right _ -> do
            e <- waitForChildren ctx
            case e of
                Just (exc :: SomeException) -> throwM exc
                Nothing -> return ()

-- TBD throttling of producer based on conumption rate.

-- | Invoked to store the result of the computation in the context and finish
-- the computation when the computation is done
gatherResult :: MonadIO m => IORef [a] -> a -> AsyncT m a
gatherResult ref r = do
    liftIO $ atomicModifyIORef ref $ \rs -> (r : rs, ())
    mzero

gather :: (MonadIO m, MonadCatch m) => AsyncT m a -> AsyncT m [a]
gather m = AsyncT $ do
    resultsRef <- liftIO $ newIORef []
    lift $ waitAsync (gatherResult resultsRef) Nothing m
    r <- liftIO $ readIORef resultsRef
    return $ Just r

-- | Run an 'AsyncT m' computation and collect the results generated by each
-- thread of the computation in a list.
wait :: (MonadIO m, MonadCatch m) => AsyncT m a -> m [a]
wait m = do
    resultsRef <- liftIO $ newIORef []
    waitAsync (gatherResult resultsRef) Nothing m
    liftIO $ readIORef resultsRef

-- | Run an 'AsyncT m' computation, wait for it to finish and discard the
-- results.
wait_ :: (MonadIO m, MonadCatch m) => AsyncT m a -> m ()
wait_ m = waitAsync (const mzero) Nothing m

------------------------------------------------------------------------------
-- Logging
------------------------------------------------------------------------------

logged :: (Loggable a, MonadIO m) => AsyncT m a -> AsyncT m a
logged m = AsyncT $ do
    ctx <- get
    case journal ctx of
        -- no replay
        CtxLog ls [] ->
            case logsRef ctx of
                Nothing -> runAsyncT m
                Just _ -> do
                    put $ ctx {journal = CtxLog (Executing : ls) []}
                    runAndLogResult m

        -- replaying the log
        CtxLog ls (r:rs) -> do
        --    dbg $ "Replay: j: " ++ show j
            case r of
                Executing -> do
                    put $ ctx {journal = CtxLog (r : ls) rs}
                    runAndLogResult m
                Result val -> do
                    let x = fmap read val
                    put $ ctx {journal = CtxLog (r : ls) rs}
                    return x

    where

    runAndLogResult action = runAsyncT $ do
        x <- action
        logResult x
        return x

    -- replaces the head of the log with the supplied result
    logResult x = AsyncT $ do
        ctx@Context{journal = CtxLog (_ : ls) _} <- get
        let entry = Result (fmap show (Just x))
        put $ ctx {journal = CtxLog (entry : ls) []}
        return $ Just ()

-- XXX enable or disable the suspension points by sending an exception to the
-- computation.
--
-- | Suspend works as an exit point with current thread state (partially done)
-- saved. The computation exits only if all the threads in the computation hit
-- the suspend point or exit normally. The threads which hit the suspension and
-- were suspended can be re-started by replaying the log. If there are threads
-- which did not suspend or did not exit, the computation will not exit. For
-- completed threads output is returned and for suspended threads the logs to
-- resume them are returned.

suspend :: MonadIO m => AsyncT m ()
suspend = logged $ AsyncT $ do
    ctx <- get
    case logsRef ctx of
        Nothing -> return $ Just ()
        Just ref ->
            case journal ctx of
                CtxLog ls [] -> do
                    -- replace the "Executing" entry at the head of the log
                    -- with a "()" so that we do not enter suspend on replay
                    liftIO $ atomicModifyIORef ref $ \logs ->
                        (Log (logResult (Just ()) : tail ls) : logs, ())
                    return Nothing
                _ -> error "Bug: replay inside suspend"
    where logResult x = Result (fmap show x)

-- | Compose a computation using previously captured logs
withLog :: Monad m => AsyncT m a -> Log -> AsyncT m a
withLog m (Log entries) = AsyncT $ do
    ctx <- get
    put $ ctx {journal = CtxLog [] (reverse entries)}
    runAsyncT m

-- | Compose a computation using previously captured list of logs. Composes a
-- group of computations, one for each log.
eachWithLog :: (MonadIO m, MonadBaseControl IO m, MonadThrow m)
    => AsyncT m a -> [Log] -> AsyncT m a
eachWithLog m logs = each logs >>= withLog m

-- | Run an 'AsyncT m' computation with logging enabled and collect the results
-- or logs generated by each thread of the computation.
waitLogged :: (MonadIO m, MonadCatch m) => AsyncT m a -> m ([a], [Log])
waitLogged m = do
    resultsRef <- liftIO $ newIORef []
    lref <- liftIO $ newIORef []
    waitAsync (gatherResult resultsRef) (Just lref) m
    res <- liftIO $ readIORef resultsRef
    logs <- liftIO $ readIORef lref
    return (res, logs)

-- | Run an 'AsyncT m' computation with logging enabled, wait for it to finish
-- and discard the results. If the computation suspends collect the logs to
-- replay later.
waitLogged_ :: (MonadIO m, MonadCatch m) => AsyncT m a -> m [Log]
waitLogged_ m = do
    lref <- liftIO $ newIORef []
    waitAsync (const mzero) (Just lref) m
    logs <- liftIO $ readIORef lref
    return logs
